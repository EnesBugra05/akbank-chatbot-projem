# ==============================================================================
# GEREKLÄ° KÃœTÃœPHANELER (app.py)
# AmaÃ§: Streamlit web arayÃ¼zÃ¼ ve RAG zinciri iÃ§in gerekli tÃ¼m
#       Python kÃ¼tÃ¼phanelerini iÃ§e aktarmak.
# ==============================================================================
import streamlit as st  # Web arayÃ¼zÃ¼nÃ¼ (butonlar, metin kutularÄ± vb.) oluÅŸturmak iÃ§in
import os               # Ä°ÅŸletim sistemiyle etkileÅŸim iÃ§in (API anahtarÄ±nÄ± ayarlamak, dosya yolunu kontrol etmek)
import pandas as pd       # (Bu kodda doÄŸrudan kullanÄ±lmÄ±yor ama genellikle veri gÃ¶stermek iÃ§in eklenir)
from tqdm import tqdm     # (Bu kodda doÄŸrudan kullanÄ±lmÄ±yor, Colab'de kullanÄ±lmÄ±ÅŸtÄ±)

# --- LangChain KÃ¼tÃ¼phaneleri ---
from langchain_text_splitters import RecursiveCharacterTextSplitter # (Bu dosyada gerek yok ama zararÄ± da yok)
from langchain_core.documents import Document                     # (Bu dosyada gerek yok ama zararÄ± da yok)
from langchain_chroma import Chroma                     # Diskten 'chroma_db' veritabanÄ±nÄ± yÃ¼klemek iÃ§in
from langchain_huggingface import HuggingFaceEmbeddings # VeritabanÄ±nÄ± yÃ¼klerken hangi embedding modelini kullandÄ±ÄŸÄ±mÄ±zÄ± belirtmek iÃ§in
from langchain_google_genai import ChatGoogleGenerativeAI # RAG zincirinin beyni olan LLM'i (Gemini) yÃ¼klemek iÃ§in
from langchain_core.prompts import PromptTemplate       # LLM'e vereceÄŸimiz talimat ÅŸablonu (Prompt) iÃ§in
from langchain_core.runnables import RunnablePassthrough # Zincir iÃ§inde kullanÄ±cÄ± sorusunu deÄŸiÅŸtirmeden aktarmak iÃ§in
from langchain_core.output_parsers import StrOutputParser # LLM'in cevabÄ±nÄ± temiz bir metne (string) dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in

# ==============================================================================
# YENÄ° EKLENDÄ°: KENAR Ã‡UBUÄU (SIDEBAR) HAKKINDA KUTUSU
# ==============================================================================
st.sidebar.title("Proje HakkÄ±nda â„¹ï¸")
st.sidebar.info(
    "Bu chatbot, Akbank GenAI Bootcamp projesi iÃ§in geliÅŸtirilmiÅŸtir.\n\n"
    "RAG (Retrieval-Augmented Generation) mimarisi kullanÄ±larak, "
    "ÅŸarkÄ± sÃ¶zlerinin bir kÄ±smÄ±nÄ± yazdÄ±ÄŸÄ±nÄ±zda o ÅŸarkÄ±nÄ±n adÄ±nÄ±, "
    "sanatÃ§Ä±sÄ±nÄ± ve tÃ¼rÃ¼nÃ¼ bulur."
)
st.sidebar.markdown("---") # AyÄ±rÄ±cÄ± Ã§izgi

# ==============================================================================
# GOOGLE API ANAHTARI AYARI (DEPLOY Ä°Ã‡Ä°N SON VERSÄ°YON: TRY-EXCEPT)
# ==============================================================================

# Bu fonksiyon, en basit ve en saÄŸlam yÃ¶ntemi kullanÄ±r:
# 1. 'st.secrets'tan anahtarÄ± okumayÄ± Dener (try).
# 2. BaÅŸarÄ±lÄ± olursa (Cloud'dayÄ±z demektir), anahtarÄ± dÃ¶ndÃ¼rÃ¼r.
# 3. Hata alÄ±rsa (Lokal'deyiz demektir),
#    kenar Ã§ubuÄŸundaki metin kutusunu gÃ¶sterir.

def get_google_api_key():
    try:
        # Ã–nce Streamlit Cloud Secrets'Ä± okumayÄ± DENE
        return st.secrets["GOOGLE_API_KEY"]
    except:
        # EÄŸer 'secrets' yoksa (Lokal) veya anahtar tanÄ±mlÄ± deÄŸilse:
        # Kenar Ã§ubuÄŸundan (Lokal) anahtarÄ± iste
        return st.sidebar.text_input(
            "Google API AnahtarÄ±nÄ±zÄ± Buraya YapÄ±ÅŸtÄ±rÄ±n:",
            type="password",
            help="API anahtarÄ±nÄ±zÄ± Google AI Studio'dan alabilirsiniz."
        )

# Fonksiyonu Ã§aÄŸÄ±r ve anahtarÄ± al
api_key = get_google_api_key()

# AnahtarÄ±n alÄ±nÄ±p alÄ±nmadÄ±ÄŸÄ±nÄ± kontrol et
if api_key:
    # AnahtarÄ±, LangChain kÃ¼tÃ¼phanelerinin otomatik olarak okuyacaÄŸÄ±
    # 'os.environ' (ortam deÄŸiÅŸkeni) iÃ§ine ata.
    os.environ["GOOGLE_API_KEY"] = api_key
else:
    # EÄŸer kullanÄ±cÄ± henÃ¼z bir anahtar girmemiÅŸse (veya Secrets'ta da yoksa):
    # Sol kenar Ã§ubuÄŸuna bir uyarÄ± koy
    st.sidebar.warning("LÃ¼tfen sol kenar Ã§ubuÄŸundan Google API anahtarlarÄ±nÄ±zÄ± girin.")
    # AnahtarÄ± girmeden uygulamanÄ±n geri kalanÄ±nÄ±n Ã§alÄ±ÅŸmasÄ±nÄ± durdur
    st.stop()
# ==============================================================================
# RAG ZÄ°NCÄ°RÄ°NÄ° YÃœKLEME FONKSÄ°YONU (HÃ¼cre 4'Ã¼n GeliÅŸmiÅŸ Hali)
# AmaÃ§: RAG zincirini (Retriever, Prompt, LLM) kuran ana fonksiyon.
# ==============================================================================

# @st.cache_resource: Bu, Streamlit iÃ§in HAYATÄ° bir optimizasyon komutudur.
@st.cache_resource
def load_rag_chain():
    """
    (Fonksiyon aÃ§Ä±klamasÄ± - Docstring)
    Colab'de oluÅŸturulan 'chroma_db' veritabanÄ±nÄ± diskten yÃ¼kler
    ve RAG zincirini kurar.
    """
    # KullanÄ±cÄ±ya modelin yÃ¼klendiÄŸini bildiren bir durum mesajÄ±
    st.sidebar.info("RAG Zinciri ve Model YÃ¼kleniyor...")
    
    # --- 1. Retriever'Ä± Kur (VeritabanÄ± YÃ¼kleme) ---
    model_name = "sentence-transformers/all-MiniLM-L6-v2"
    embeddings = HuggingFaceEmbeddings(model_name=model_name)
    
    # 'app.py'nin Ã§alÄ±ÅŸtÄ±ÄŸÄ± dizinde 'chroma_db' adÄ±nda bir klasÃ¶r ara.
    if not os.path.exists("chroma_db"):
        # EÄŸer klasÃ¶r bulunamazsa:
        # Ana ekrana bÃ¼yÃ¼k bir HATA mesajÄ± bas.
        st.error(
            "HATA: 'chroma_db' klasÃ¶rÃ¼ bulunamadÄ±! "
            "LÃ¼tfen Colab'den indirdiÄŸiniz 'chroma_db' klasÃ¶rÃ¼nÃ¼ 'app.py' dosyasÄ±nÄ±n yanÄ±na kopyalayÄ±n."
        )
        st.stop() # UygulamayÄ± durdur
        
    # 'chroma_db' klasÃ¶rÃ¼nÃ¼ diskten yÃ¼kle ve 'vectorstore' nesnesini oluÅŸtur.
    vectorstore = Chroma(persist_directory="chroma_db", embedding_function=embeddings)
    
    # Optimize ettiÄŸimiz en iyi ayar (Colab HÃ¼cre 4'teki gibi):
    retriever = vectorstore.as_retriever(search_kwargs={"k": 1}) 
    
    # --- 2. Prompt'u Kur (Colab HÃ¼cre 4'teki gibi) ---
    template = """
    Sana verilen BaÄŸlam'Ä± kullanarak kullanÄ±cÄ±nÄ±n Soru'sunu cevapla. CevabÄ±nÄ± SADECE bu baÄŸlamdaki bilgilere dayanarak ver. EÄŸer baÄŸlamda cevap yoksa, 'Bu konuda bilgim yok.' de.
    BaÄŸlam:
    {context}
    Soru: {question}
    Cevap:
    """
    prompt = PromptTemplate.from_template(template)

    # --- 3. LLM'i Kur (Colab HÃ¼cre 4'teki gibi) ---
    llm = ChatGoogleGenerativeAI(model="gemini-pro-latest", temperature=0)

    # --- 4. Zinciri (Chain) OluÅŸtur (Colab HÃ¼cre 4'teki gibi) ---
    rag_chain = (
        {"context": retriever, "question": RunnablePassthrough()}  # AdÄ±m 1: Context'i bul, soruyu aktar
        | prompt                                                   # AdÄ±m 2: Prompt'u doldur
        | llm                                                      # AdÄ±m 3: LLM'e sor
        | StrOutputParser()                                        # AdÄ±m 4: CevabÄ± metne Ã§evir
    )
    
    # Model yÃ¼klemesi bittiÄŸinde kenar Ã§ubuÄŸundaki 'info' mesajÄ±nÄ±
    # 'success' (baÅŸarÄ±) mesajÄ± ile deÄŸiÅŸtir.
    st.sidebar.success("RAG Zinciri ve Model BaÅŸarÄ±yla YÃ¼klendi!")
    return rag_chain # HafÄ±zaya (cache) alÄ±nacak olan RAG zincirini dÃ¶ndÃ¼r.

# ==============================================================================
# WEB ARAYÃœZÃœ (STREAMLIT) - TASARIM GÃœNCELLENDÄ°
# ==============================================================================

# YENÄ° EKLENDÄ°: BaÅŸlÄ±ÄŸÄ± ortalamak ve stilleri iyileÅŸtirmek iÃ§in HTML/CSS
st.markdown("""
<style>
h1 {
    font-size: 2.0rem   !important; /* BaÅŸlÄ±ÄŸÄ± biraz bÃ¼yÃ¼ttÃ¼m */
    text-align: center;          /* BAÅLIÄI ORTALA */
    padding-bottom:20px;         /* AltÄ±na biraz boÅŸluk */
    margin-bottom:80px;         /* Ã‡izginin altÄ±na boÅŸluk */
}

/* YENÄ° EKLENDÄ°: Merhaba yazÄ±sÄ±nÄ± aÅŸaÄŸÄ± itmek iÃ§in */
.welcome-text {
    margin-top: 30px; /* BaÅŸlÄ±ktaki 80px boÅŸluÄŸa EK olarak 30px daha boÅŸluk ekler */
    font-size: 1.1rem; /* YazÄ±yÄ± biraz bÃ¼yÃ¼telim */
}

/* Metin giriÅŸ kutusunun gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼ iyileÅŸtir */
.stTextInput > div > div > input {
    font-size: 1.1rem;
    padding-top: 10px;
    padding-bottom: 10px;
}
</style>

<h1>ğŸµ ÅarkÄ± SÃ¶zlerinden ÅarkÄ± Bulma Chatbot'u ğŸµ</h1>
""", unsafe_allow_html=True)

# DEÄÄ°ÅTÄ°: 'Merhaba...' satÄ±rÄ±nÄ± da st.markdown iÃ§ine alÄ±p sÄ±nÄ±fÄ± uyguluyoruz
st.markdown('<p class="welcome-text">Merhaba, nasÄ±l yardÄ±mcÄ± olabilirim?</p>', unsafe_allow_html=True)

# --- Ana Uygulama MantÄ±ÄŸÄ± ---
try:
    # ADIM 1: RAG zincirini yÃ¼kle.
    chain = load_rag_chain()
    
    # ADIM 2: KullanÄ±cÄ±dan soru almak iÃ§in bir metin giriÅŸ kutusu oluÅŸtur.
    # YENÄ° EKLENDÄ°: 'placeholder' (silik Ã¶rnek metin) eklendi
    user_question = st.text_input(
        "Hadi bana bulmak istediÄŸin ÅŸarkÄ±nÄ±n sÃ¶zlerini sÃ¶yle...",
        placeholder=""
    )
    
    # YENÄ° EKLENDÄ°: Ã–rnek sorularÄ± gÃ¶steren bir alt baÅŸlÄ±k
    st.caption("Ã–rnek kullanÄ±m: 'AÅŸkÄ±n kazanmasÄ± iÃ§in ayrÄ± gitme' sÃ¶zÃ¼ geÃ§en ÅŸarkÄ± hangisi, kim sÃ¶ylÃ¼yor ve tÃ¼rÃ¼ nedir?")

    # ADIM 3: EÄŸer kullanÄ±cÄ± bir soru yazÄ±p 'Enter'a bastÄ±ysa...
    if user_question:
        # 'st.spinner', kullanÄ±cÄ±ya "bekle" mesajÄ± gÃ¶steren
        # dÃ¶nen bir animasyon baÅŸlatÄ±r.
        with st.spinner("ÅarkÄ± aranÄ±yor... ğŸ¶"):
            # RAG zincirini kullanÄ±cÄ±nÄ±n sorusuyla Ã§alÄ±ÅŸtÄ±r (invoke).
            cevap = chain.invoke(user_question) 
        
        # 'with st.spinner' bloÄŸu bittiÄŸinde (cevap alÄ±ndÄ±ÄŸÄ±nda)
        # animasyon otomatik olarak kaybolur.
        
        # ADIM 4: Gelen cevabÄ± kontrol et.
        if "Bu konuda bilgim yok" in cevap:
            # BaÅŸarÄ±sÄ±zlÄ±k durumu: LLM bir ÅŸey bulamadÄ±.
            st.error("ÃœzgÃ¼nÃ¼m bulamadÄ±m. FarklÄ± bir sÃ¶z dizisi deneyebilirsin.")
        else:
            # BaÅŸarÄ± durumu: LLM bir cevap buldu.
            st.success("Ä°ÅŸte buldum!") 
            st.markdown(f"**Cevap:** {cevap}")

except Exception as e:
    # 'load_rag_chain' veya 'chain.invoke' sÄ±rasÄ±nda bir hata oluÅŸursa
    st.error(f"Bir hata oluÅŸtu: {e}")
    st.error("LÃ¼tfen 'chroma_db' klasÃ¶rÃ¼nÃ¼n doÄŸru yerde olduÄŸundan veya API anahtarÄ±nÄ±zÄ±n doÄŸru olduÄŸundan emin olun.")