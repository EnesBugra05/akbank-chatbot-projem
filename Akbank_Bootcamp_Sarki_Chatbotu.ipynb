{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxldr2J3MjDu",
        "outputId": "e7deac58-45eb-4dbe-c85c-93613a80fed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ HÜCRE 1: Gerekli kütüphaneler kuruluyor...\n",
            "\n",
            "✅ Kurulum tamamlandı.\n",
            "\n",
            "⚠️ >>>>> KESİNLİKLE YAP: Şimdi menüden 'Runtime' -> 'Restart session' diyerek oturumu yeniden başlat! <<<<< ⚠️\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# HÜCRE 1: KÜTÜPHANE KURULUMU\n",
        "# Amaç: Proje için gerekli olan tüm Python kütüphanelerini kurmak ve\n",
        "#       Google Colab ortamının bu kütüphaneleri doğru şekilde tanımasını sağlamak.\n",
        "# ==============================================================================\n",
        "print(\"▶️ HÜCRE 1: Gerekli kütüphaneler kuruluyor...\")\n",
        "\n",
        "# !pip komutu, Colab'in sanal makinesine paket kurmamızı sağlar.\n",
        "# -U (upgrade) bayrağı, paketlerin en son sürümüne güncellenmesini sağlar.\n",
        "# -q (quiet) bayrağı, kurulum sırasında oluşan uzun çıktı metinlerini gizler.\n",
        "# Kütüphaneleri daha okunaklı olması için ayırarak kuruyoruz:\n",
        "!pip install -U -q \\\n",
        "    langchain \\\n",
        "    langchain-google-genai \\\n",
        "    langchain-huggingface \\\n",
        "    langchain-chroma \\\n",
        "    sentence-transformers \\\n",
        "    pandas \\\n",
        "    tqdm\n",
        "\n",
        "# KURULAN KÜTÜPHANELERİN GÖREVLERİ:\n",
        "# ------------------------------------\n",
        "# langchain: RAG (Retrieval-Augmented Generation) mimarisinin \"beyni\".\n",
        "#            Veri akışını (chain), prompt'ları ve modelleri yöneten ana kütüphane.\n",
        "#\n",
        "# langchain-google-genai: LangChain'in Google Gemini (gemini-pro) modeliyle\n",
        "#                         iletişim kurmasını sağlayan entegrasyon paketi. LLM'imiz budur.\n",
        "#\n",
        "# langchain-huggingface: LangChain'in Hugging Face modellerini kullanmasını sağlar.\n",
        "#                        Bunu, şarkı sözlerini vektöre çevirecek olan Embedding\n",
        "#                        modeli ('all-MiniLM-L6-v2') için kullanıyoruz.\n",
        "#\n",
        "# langchain-chroma: LangChain'in ChromaDB vektör veritabanı ile konuşmasını sağlar.\n",
        "#                   (Veritabanına vektör ekleme, sorgulama vb. için)\n",
        "#\n",
        "# sentence-transformers: Şarkı sözlerini (metin) anlamsal vektörlere (sayısal temsillere)\n",
        "#                        dönüştürmek için kullandığımız 'all-MiniLM-L6-v2'\n",
        "#                        modelini içeren asıl kütüphane.\n",
        "#\n",
        "# pandas: Veri setini (şarkı sözleri, sanatçılar) okumak, işlemek ve\n",
        "#         zenginleştirmek için kullanılan temel veri analizi kütüphanesi.\n",
        "#\n",
        "# tqdm: Özellikle binlerce şarkı sözünü işlerken ilerleme durumunu\n",
        "#       gösteren bir ilerleme çubuğu (progress bar) oluşturur.\n",
        "\n",
        "print(\"\\n✅ Kurulum tamamlandı.\")\n",
        "\n",
        "# --- ÇOK ÖNEMLİ NOT ---\n",
        "# Google Colab, oturum başladığında belirli kütüphaneleri hafızaya yükler.\n",
        "# 'pip install -U' ile bu kütüphanelerin yeni sürümlerini kursak bile,\n",
        "# Colab 'Restart session' yapılana kadar hafızadaki eski sürümleri\n",
        "# kullanmaya devam edebilir.\n",
        "#\n",
        "# Bu durum, özellikle 'langchain' gibi hızla güncellenen kütüphanelerde\n",
        "# 'ImportError' veya 'AttributeError' gibi hatalara yol açar.\n",
        "# Oturumu yeniden başlatmak (Restart session), Colab'in yeni kurulan\n",
        "# paketleri tanımasını ve doğru sürümü yüklemesini garanti altına alır.\n",
        "print(\"\\n⚠️ >>>>> KESİNLİKLE YAP: Şimdi menüden 'Runtime' -> 'Restart session' diyerek oturumu yeniden başlat! <<<<< ⚠️\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# HÜCRE 2: GEREKLİ MODÜLLERİN İÇE AKTARILMASI VE API ANAHTARI\n",
        "# Amaç: (Hücre 1'de kurduğumuz) kütüphanelerden ihtiyaç duyduğumuz\n",
        "#       spesifik fonksiyonları/sınıfları kodumuza dahil etmek ve\n",
        "#       Google API anahtarını güvenli bir şekilde Colab ortamına tanıtmak.\n",
        "# ==============================================================================\n",
        "print(\"▶️ HÜCRE 2: Gerekli modüller içe aktarılıyor ve API anahtarı ayarlanıyor...\")\n",
        "\n",
        "# --- Standart Kütüphaneler ---\n",
        "import os\n",
        "    # 'os' (Operating System): İşletim sistemiyle ilgili işlemler yapmak için kullanılır.\n",
        "    # Örneğin, klasörlerin var olup olmadığını (os.path.exists) kontrol etmek veya\n",
        "    # 'environment variables' (ortam değişkenleri) içine API anahtarımızı eklemek için.\n",
        "\n",
        "import getpass\n",
        "    # 'getpass': Kullanıcıdan parola/API anahtarı gibi gizli bilgileri\n",
        "    # terminalde/notebook hücresinde GÖRÜNMEDEN (yankılanmadan) almayı sağlar.\n",
        "    # Bu, API anahtarımızın kopyalanmasını veya ekran görüntülerinde görünmesini engeller.\n",
        "\n",
        "import pandas as pd\n",
        "    # 'pandas': Veri setimizi (.csv, .txt) okumak, DataFrame adı verilen\n",
        "    # tablosal bir yapıda tutmak ve manipüle etmek (örn: 'sanatçı' sütunu eklemek) için.\n",
        "\n",
        "from tqdm import tqdm\n",
        "    # 'tqdm' (tahammül): Uzun süren döngüler (örn: binlerce şarkıyı okuma) için\n",
        "    # bir ilerleme çubuğu (progress bar) gösterir. Ne kadar iş kaldığını görmemizi sağlar.\n",
        "\n",
        "from google.colab import files\n",
        "    # 'files': Google Colab'e özgü bu modül, 'kaggle.json' gibi dosyaları\n",
        "    # lokal bilgisayarımızdan Colab ortamına yüklememizi sağlar (files.upload()).\n",
        "\n",
        "# --- LangChain Kütüphaneleri (RAG Mimarisi için) ---\n",
        "\n",
        "# DÜZELTME: Doğru ve en güncel import yolu eklendi\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "    # RAG için kritik bir araç. Uzun şarkı sözlerini, modelin anlayabileceği\n",
        "    # daha küçük ve anlamlı parçalara (chunks) bölmek için kullanılır.\n",
        "    # 'Recursive' olması, metni \"anlamlı\" yerlerden (örn: paragraf, satır)\n",
        "    # bölmeye çalışması anlamına gelir.\n",
        "\n",
        "# DÜZELTME: Document'ın da doğru import yolu\n",
        "from langchain_core.documents import Document\n",
        "    # LangChain'in standart veri yapısı. Şarkı sözlerini (page_content) ve\n",
        "    # o söze ait üst veriyi (metadata: sanatçı, şarkı adı) bir arada tutan\n",
        "    # bir \"belge\" nesnesi oluşturmamızı sağlar.\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "    # Vektör veritabanımız olan ChromaDB ile etkileşim kurmamızı sağlayan sınıf.\n",
        "    # Vektörleri kaydetmek (from_documents) ve veritabanını yüklemek (persist_directory)\n",
        "    # için kullanılır.\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "    # Şarkı sözü parçalarını (metin) vektörlere (sayılar) dönüştürecek olan\n",
        "    # Hugging Face modelini (all-MiniLM-L6-v2) yüklemek için kullanılır.\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "    # RAG zincirinin son aşamasında, soruyu ve bulunan bağlamı (şarkı sözü)\n",
        "    # anlayıp cevap verecek olan asıl 'Large Language Model' (LLM) olan\n",
        "    # Gemini-Pro modelini yüklememizi sağlar.\n",
        "\n",
        "# RetrievalQA import'u kaldırıldı, çünkü Hücre 4'te LCEL kullanıyoruz.\n",
        "    # Not: Eski LangChain'de 'RetrievalQA' sınıfı kullanılırdı.\n",
        "    # Biz ise daha modern, esnek ve güçlü olan LCEL (LangChain Expression Language)\n",
        "    # boru hattı ('|' operatörü ile) yöntemini (Hücre 4'te) kullanıyoruz.\n",
        "\n",
        "# --- API Anahtarı Ayarlaması ---\n",
        "\n",
        "# 'os.environ', Colab ortamının \"ortam değişkenlerini\" tutan bir sözlüktür.\n",
        "# Kütüphaneler (örn: langchain_google_genai) API anahtarını otomatik olarak\n",
        "# \"GOOGLE_API_KEY\" adlı değişkenden arar.\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    # Eğer anahtar daha önce ayarlanmamışsa, kullanıcıdan güvenli bir şekilde iste:\n",
        "    print(\"API Anahtarı bulunamadı. Lütfen şimdi girin:\")\n",
        "\n",
        "    # 'getpass.getpass' ile kullanıcıdan anahtarı görünmez bir şekilde al\n",
        "    # ve 'os.environ' içine ata.\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Lütfen Google API Anahtarınızı yapıştırın:\")\n",
        "    print(\"API Anahtarı başarıyla ayarlandı.\")\n",
        "else:\n",
        "    # Eğer anahtar zaten ayarlanmışsa (örn: notebook'u tekrar çalıştırıyorsak)\n",
        "    # tekrar sormaya gerek yok.\n",
        "    print(\"API Anahtarı zaten ayarlanmış.\")\n",
        "\n",
        "print(\"\\n✅ Modüller ve API anahtarı hazır.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn0_co5YMo4q",
        "outputId": "79baf04e-6d7e-4049-f46b-69e7a1ec7091"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ HÜCRE 2: Gerekli modüller içe aktarılıyor ve API anahtarı ayarlanıyor...\n",
            "API Anahtarı bulunamadı. Lütfen şimdi girin:\n",
            "Lütfen Google API Anahtarınızı yapıştırın:··········\n",
            "API Anahtarı başarıyla ayarlandı.\n",
            "\n",
            "✅ Modüller ve API anahtarı hazır.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# HÜCRE 3: VERİ HAZIRLAMA VE VEKTÖR VERİTABANI OLUŞTURMA (SADECE 1 KEZ ÇALIŞTIR)\n",
        "# Amaç: Ham veriyi (şarkı sözü .txt dosyaları) Kaggle'dan indirmek,\n",
        "#       bu veriyi yapılandırmak (Pandas DataFrame),\n",
        "#       eksik bilgileri (sanatçı adı) manuel bir harita ile zenginleştirmek,\n",
        "#       veriyi RAG için parçalamak (chunking) ve\n",
        "#       bu parçaları vektörleştirerek kalıcı bir 'chroma_db' veritabanına kaydetmek.\n",
        "#\n",
        "# NOT: Bu hücre, veritabanını SIFIRDAN oluşturur ve 'chroma_db' klasörünün\n",
        "#      üzerine yazar. Bu nedenle SADECE BİR KEZ çalıştırılmalıdır.\n",
        "# ==============================================================================\n",
        "print(\"▶️ HÜCRE 3: Veri seti hazırlanıyor ve vektör veritabanı SIFIRDAN oluşturuluyor...\")\n",
        "\n",
        "# --- 1. Veri İndirme (Kaggle) ---\n",
        "# 'Lyrics' klasörü Colab ortamında zaten yoksa, indirme işlemini başlat.\n",
        "# Bu, hücreyi tekrar çalıştırdığımızda veriyi tekrar indirmemizi engeller.\n",
        "if not os.path.exists('Lyrics'):\n",
        "    print(\"Veri seti 'Lyrics' klasörü bulunamadı, Kaggle'dan indiriliyor...\")\n",
        "\n",
        "    # Kaggle API'sinin çalışması için 'kaggle.json' API anahtar dosyası gerekir.\n",
        "    # Eğer bu dosya da ortamda yoksa, kullanıcıdan yüklemesini iste.\n",
        "    if not os.path.exists('kaggle.json'):\n",
        "        print(\"Lütfen 'kaggle.json' dosyasını seçin:\")\n",
        "        files.upload() # Colab'in dosya yükleme arayüzünü açar.\n",
        "\n",
        "    # Kaggle API'sinin 'kaggle.json' dosyasını bulabileceği standart yolu oluştur.\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "\n",
        "    # 'kaggle.json' dosyasına sadece sahibinin (bizim) okuma/yazma izni ver.\n",
        "    # Bu, Kaggle API'sinin güvenlik uyarısı vermemesi için gereklidir.\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "    # Kaggle API'sini kullanarak veri setini indir.\n",
        "    !kaggle datasets download -d anil1055/turkish-music-spectograms\n",
        "\n",
        "    # İndirilen .zip dosyasını aç (-q: sessiz, -o: üzerine yaz)\n",
        "    # ve mevcut dizine çıkart (-d .).\n",
        "    !unzip -q -o turkish-music-spectograms.zip -d .\n",
        "    print(\"Veri seti başarıyla indirildi ve 'Lyrics' klasörüne açıldı.\")\n",
        "else:\n",
        "    print(\"Veri seti 'Lyrics' klasörü zaten mevcut, indirme adımı atlandı.\")\n",
        "\n",
        "\n",
        "# --- 2. Veriyi Okuma ve Yapılandırma ---\n",
        "# Veri seti, 'Lyrics' klasörü altında 'Pop', 'Rock', 'Arabesk' gibi\n",
        "# alt klasörlerde .txt dosyaları olarak durmaktadır.\n",
        "\n",
        "song_data = [] # Okunan şarkı bilgilerini depolamak için boş bir liste.\n",
        "lyrics_folder_path = 'Lyrics' # Ana veri klasörünün yolu.\n",
        "\n",
        "# 'os.walk', bir klasör ağacında (tüm alt klasörler dahil) gezinmemizi sağlar.\n",
        "# 'tqdm' ile bu gezinme işlemini bir ilerleme çubuğu ile gösteriyoruz.\n",
        "for root, dirs, files_list in tqdm(os.walk(lyrics_folder_path), desc=\"Şarkılar okunuyor\"):\n",
        "    for file in files_list:\n",
        "        # Sadece .txt uzantılı dosyaları (şarkı sözlerini) işle\n",
        "        if file.endswith('.txt'):\n",
        "            # Dosya yolunu (root) parçalayarak ('/') kategori adını al.\n",
        "            # Örn: 'Lyrics/Pop' -> ['Lyrics', 'Pop'] -> 'Pop'\n",
        "            path_parts = root.split(os.sep)\n",
        "            kategori = path_parts[-1] if len(path_parts) > 1 else \"Bilinmiyor\"\n",
        "\n",
        "            # Dosya adından uzantıyı (.txt) ayırarak şarkı adını al.\n",
        "            # Örn: 'Aşkın Mapushane.txt' -> 'Aşkın Mapushane'\n",
        "            sarki_adi = os.path.splitext(file)[0]\n",
        "\n",
        "            # Dosyanın tam yolunu oluştur\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "            try:\n",
        "                # Dosyayı 'utf-8' encoding ile aç ve içeriğini (lyrics) oku.\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    lyrics = f.read()\n",
        "\n",
        "                    # Şarkı için bir sözlük oluştur\n",
        "                    song_info = {'kategori': kategori, 'sarki_adi': sarki_adi, 'sozler': lyrics}\n",
        "\n",
        "                    # Bu sözlüğü ana listemize ekle\n",
        "                    song_data.append(song_info)\n",
        "            except Exception:\n",
        "                # Bazı .txt dosyaları bozuk olabilir veya encoding hatası verebilir.\n",
        "                # Bu dosyaları atla (pass) ve yoluna devam et.\n",
        "                pass\n",
        "# Toplanan tüm şarkı sözlüğü listesini bir Pandas DataFrame'e dönüştür.\n",
        "# Bu, veriyi temizlemeyi ve zenginleştirmeyi kolaylaştırır.\n",
        "df_temiz = pd.DataFrame(song_data)\n",
        "print(f\"\\n{len(df_temiz)} adet şarkı sözü okundu ve DataFrame oluşturuldu.\")\n",
        "\n",
        "\n",
        "# --- 3. Veri Zenginleştirme (Kritik Adım) ---\n",
        "# KULLANILAN VERİ SETİ (Kaggle) SADECE ŞARKI SÖZÜ VE KATEGORİ İÇERİR,\n",
        "# ANCAK 'SANATÇI' BİLGİSİNİ İÇERMEZ.\n",
        "# Chatbot'un \"Bu şarkı kimin?\" sorusuna cevap verebilmesi için\n",
        "# 'sanatçi' bilgisini verimize eklememiz gerekiyor.\n",
        "# Bu projede bu sorun, manuel olarak hazırlanmış bir 'Şarkı: Sanatçı'\n",
        "# listesi (user_text) üzerinden çözülmüştür.\n",
        "\n",
        "# Manuel olarak oluşturulmuş \"Şarkı Adı: Sanatçı Adı\" eşleştirme metni.\n",
        "# BU LİSTE, PROJENİN DOĞRU ÇALIŞMASI İÇİN TAM VE EKSİKSİZ OLMALIDIR.\n",
        "user_text = \"\"\"\n",
        "Pop ve Rock\n",
        "Aşkın Mapushane: Haluk Levent\n",
        "Bir Sevmek Bin Defa: 3 Hürel\n",
        "Öpmek İsterdim: Haluk Levent\n",
        "Dağları Deldim: Haluk Levent\n",
        "Dibine Kadar: Duman\n",
        "Birileri Var: Duman\n",
        "Ben Böyleyim: Athena\n",
        "Kimdir O: Athena\n",
        "Aman Aman: Duman\n",
        "Öpücük: Simge\n",
        "Vazgeçtim Dünyadan: Şebnem Ferah\n",
        "Cambaz: Mor ve Ötesi\n",
        "Ben Seni Arayamam: Cem Adrian\n",
        "Pencere: Cem Adrian\n",
        "Bir Kadın Çizeceksin: maNga\n",
        "Sokak Lambası: Yüksek Sadakat\n",
        "Dursun Zaman: maNga (ft. Göksel)\n",
        "Mor Yazma: Umut Kaya\n",
        "Bu Akşam: Duman\n",
        "Dünyanın Sonuna Doğmuşum: maNga\n",
        "Can Kırıkları: Şebnem Ferah\n",
        "Koca Yaşlı: Adamlar\n",
        "Bitti Rüya: Pinhani\n",
        "Oyunbozan: Mor ve Ötesi\n",
        "Senden Daha Güzel: Duman\n",
        "İyi de Banane: Model\n",
        "Her Şeyi Yak: Duman\n",
        "Kime Ne: Duman\n",
        "Çakıl Taşları: Şebnem Ferah\n",
        "Cevapsız Sorular: maNga\n",
        "Saydım: Ogün Sanlısoy\n",
        "Yaz Yaz Yaz: Ajda Pekkan\n",
        "Rüyalarda Buruşmuşum: Adamlar\n",
        "Ben Öldüm: Pinhani\n",
        "Yıldızların Altında: Kargo\n",
        "Seni Kendime Sakladım: Duman\n",
        "Çatal Yürek: Haluk Levent\n",
        "Islak Islak: Cem Karaca\n",
        "Sil Baştan: Şebnem Ferah\n",
        "Sevda Çiçeği: Mor ve Ötesi\n",
        "Öyle Dertli: Duman\n",
        "Yaşamak Var Ya: Athena\n",
        "Arsız Gönül: Athena\n",
        "Afili Yalnızlık: Emre Aydın\n",
        "Köprüaltı: Duman\n",
        "Kelebekler: Pinhani\n",
        "Tamirci Çırağı: Cem Karaca\n",
        "Yollarda Bulurum: Haluk Levent\n",
        "Bu Aşk Fazla: Şebnem Ferah\n",
        "Yalnız: Duman\n",
        "Mavi: Pinhani\n",
        "Haydi Gel İçelim: Duman\n",
        "Kafama Göre: Athena\n",
        "Düşler Sokağı: Feridun Düzağaç\n",
        "Resimdeki Gözyaşları: Cem Karaca\n",
        "Elleri Ellerime: Duman\n",
        "Sende Yap: Pinhani\n",
        "Vurdum En Dibe: Duman\n",
        "Mayın Tarlası: maNga\n",
        "Bir Derdim Var: Mor ve Ötesi\n",
        "Yolla: Tarkan\n",
        "Sahici: Tarkan\n",
        "Efkar Gecesi: Duman\n",
        "Olmaz Deme: Tarkan\n",
        "Hadi Çal: Tarkan\n",
        "Nasıl olacak: Tarkan\n",
        "Hayatım Kaymış: Can Bonomo\n",
        "Vanilya: Simge\n",
        "Çağır: Mabel Matiz\n",
        "Roket: Mabel Matiz\n",
        "Çınlama: Mabel Matiz\n",
        "Arıyorum: Edis\n",
        "Miş Miş: Simge\n",
        "İsabelle: Simge\n",
        "Numaracı: Simge\n",
        "Ayrı Gitme: Aleyna Tilki\n",
        "Masum: Zeynep Bastık\n",
        "Zaman: Zeynep Bastık\n",
        "İltimas: Gülşen ft. Murat Boz\n",
        "Dudak: Edis\n",
        "Tövbeler Olsun: Tarkan\n",
        "Sor: Tarkan\n",
        "Hoşuna mı Gidiyor: Ece Seçkin ft. Ozan Doğulu\n",
        "Arada Sırada: Sinan Akçıl\n",
        "Yaz Gülü: İrem Derici\n",
        "Papatya: Teoman\n",
        "Ayıp Yani: Demet Akalın\n",
        "Ben Olsaydım: Simge\n",
        "Bu Nasıl Aşk: Hadise\n",
        "Dudaklarım Yeminli: Hande Yener\n",
        "Haydi Gel Benimle Ol: Sezen Aksu\n",
        "Bitter: Hadise\n",
        "Yani: Tarkan\n",
        "Kimseler Bulamasın: Mabel Matiz\n",
        "Ara: Mem Ararat\n",
        "Sahi: Mabel Matiz\n",
        "Tabi Tabi: Sinan Akçıl\n",
        "Al Aramızdan: Köfn\n",
        "Feryat: Tarkan\n",
        "Yap Bi Güzellik: Tarkan\n",
        "Diva Yorgun: Melike Şahin\n",
        "Seviyo Muyuz: İrem Derici\n",
        "Uyanda Gel: Mabel Matiz\n",
        "Nerdesin Aşkım: Hadise\n",
        "Mevsimsizim: Mabel Matiz\n",
        "Başıma Belasın: Hande Yener\n",
        "E S - Aman Aman: Ece Seçkin\n",
        "Sarışın: Sezen Aksu\n",
        "Bangır Bangır: Gülşen\n",
        "Senin Olsun: İrem Derici\n",
        "Bugün Adım Leyla: Hande Yener\n",
        "Nefes: Hande Yener\n",
        "Aslan Gibi: Kurtuluş Kuş\n",
        "Kaybet: Hande Yener\n",
        "Nankör: Hande Yener\n",
        "Aşkın Olayım: Simge\n",
        "Sana Nolmuş: Hande Yener\n",
        "Acele Etme: Hande Yener\n",
        "Olmuşum Leyla: Hande Yener\n",
        "Harcandıkça: Hande Yener\n",
        "Sevdanın Tadı: Hande Yener\n",
        "Arabesk ve Fantezi\n",
        "Batsın Bu Dünya: Orhan Gencebay\n",
        "Allahım Neydi Günahım: Kayahan\n",
        "Dertler Benim Olsun: Orhan Gencebay\n",
        "Unutamadım: Müslüm Gürses\n",
        "Duvardaki Resim: Müslüm Gürses\n",
        "Unutama Beni: Esengül\n",
        "Birkaç Damla Yaş: Müslüm Gürses\n",
        "Zor Bela: Müslüm Gürses\n",
        "Bir Telefon: Müslüm Gürses\n",
        "Hani Bekleyecektin: Müslüm Gürses\n",
        "Vazgeç Gönül: Orhan Gencebay\n",
        "Son Mektup: Müslüm Gürses\n",
        "Ağlamam Ondan: Müslüm Gürses\n",
        "Huzurum Kalmadı: Ferdi Tayfur\n",
        "Sen Aldırma: Ferdi Tayfur\n",
        "Beni Kaybettin Artık: Ferdi Tayfur\n",
        "Akşam Güneşi: Sibel Can\n",
        "Bana Sor: Ferdi Tayfur\n",
        "Bir Teselli Ver: Orhan Gencebay\n",
        "Yalan Oldu: Ferdi Tayfur\n",
        "Dil Yarası: Orhan Gencebay\n",
        "Ah Gülüm: Müslüm Gürses\n",
        "Sensiz Olmaz: Müslüm Gürses\n",
        "Yalnızım: İbrahim Tatlıses\n",
        "Kul Hatasız Olmaz: Orhan Gencebay\n",
        "Şimdi Uzaklardasın: Zeki Müren\n",
        "Sevda Yüklü Kervanlar: Ferdi Tayfur\n",
        "Yalnızım Dostlarım: İbrahim Tatlıses\n",
        "Kırılsın Ellerim: Muazzez Ersoy\n",
        "Elimde Fotoğrafın: Bergen\n",
        "Kaderimin Oyunu: Orhan Gencebay\n",
        "K Y - Yanarım: Kayahan\n",
        "Ağlamak Yok Yüreğim: Hakan Taşıyan\n",
        "Canısı: İbrahim Erkal\n",
        "Dilek Taşı: Gülden Karaböcek\n",
        "Vazgeçtim: Sezen Aksu\n",
        "Sabahçı Kahvesi: Ferdi Tayfur\n",
        "Hatıran Yeter: Ferdi Tayfur\n",
        "Doktor: Müslüm Gürses\n",
        "Sen Affetsen Ben Affetmem: Bergen\n",
        "Yorgun Yıllarım: Cengiz Kurtoğlu\n",
        "Bir Ayrılık Şarkısı: Müslüm Gürses\n",
        "Ağlıyorsam Yanıyorum: Cengiz Kurtoğlu\n",
        "Eğer Ağlıyorsam: Cengiz Kurtoğlu\n",
        "Nilüfer: Müslüm Gürses\n",
        "Güz Gülleri: Hakan Taşıyan\n",
        "Unutabilsem: Emrah\n",
        "Ahmet K - Söyle: Ahmet Kaya\n",
        "İstemem Seni: Emrah\n",
        "Neden Saçların Beyazlamış Arkadaş: Adnan Şenses\n",
        "Bir Ateşe Attın Beni: İbrahim Tatlıses\n",
        "Merak Etme Sen: Cengiz Kurtoğlu\n",
        "Hangimiz Sevmedik: Müslüm Gürses\n",
        "Gitme Sana Muhtacım: Zeki Müren\n",
        "Acıların Çocuğu: Emrah\n",
        "Sevme: Emrah\n",
        "Hazin Geliyor: Emrah\n",
        "Çare Gelmez: Ferdi Tayfur\n",
        "Yıllar Utansın: Müslüm Gürses\n",
        "Benden Bu Kadar: Müslüm Gürses\n",
        "Rap ve Alternatif\n",
        "Deli: Ezhel\n",
        "Arasan da: UZI\n",
        "Sözler Şerefsiz Oldu: Norm Ender\n",
        "Aynen: Heijan ft. Muti\n",
        "Değilim Bi Aşık: UZI\n",
        "Cindy: UZI\n",
        "Le Le: UZI\n",
        "Kayıp Kelimeler: Sagopa Kajmer\n",
        "Bu Senin Ellerinde: Sagopa Kajmer\n",
        "Meftun: Canbay & Wolker\n",
        "Konum Gizli: Heijan ft. Muti\n",
        "Neyim Var ki: Ceza ft. Sagopa Kajmer\n",
        "Hep mi Ben: UZI\n",
        "Zor: UZI\n",
        "Pişman Değilim: UZI\n",
        "Suspus: Ceza\n",
        "Ben Elimi Sana Verdim: Sagopa Kajmer\n",
        "Baybay: Ceza\n",
        "Kimsin Sen: Norm Ender\n",
        "Mekanın Sahibi: Norm Ender\n",
        "180km: luffex\n",
        "Sazımı Duvara Astım: Barış Manço\n",
        "Caney: UZI\n",
        "Ela: Reynmen\n",
        "Kalbim Çukurda: Gazapizm\n",
        "Unutulacak Dünler: Gazapizm\n",
        "Paparazzi: Murda\n",
        "Olur Mu: Gazapizm\n",
        "Aya: UZ4Y\n",
        "Karanlık Dünyam: Gazapizm\n",
        "Kafanı Boşalt: Ezhel\n",
        "Affetmem: Blok3\n",
        "Yakalarsan: UZI\n",
        "Gökyüzü: Sagopa Kajmer\n",
        "Herkes Gibisin: Cem Adrian\n",
        "Of Aman: Sagopa Kajmer\n",
        "Nerdesin: Ezhel\n",
        "Terapi: Ezhel\n",
        "Hayalin Yeri Yok: Gazapizm\n",
        "Çıktık Yine Yollara: Gazapizm\n",
        "Ararım Yarın: Murda & MERO\n",
        "Baytar: Murda\n",
        "Vur Keyfin Dibine: Murda\n",
        "Yerli Plaka: Ceza\n",
        "Yarın Ölümü Beklemek Yerine: Gazapizm\n",
        "Holocaust: Ceza\n",
        "Heyecanı Yok: Gazapizm\n",
        "İmdat: Çakal\n",
        "Umrumda Değil: UZI\n",
        "Bi Sonraki Hayatımda Gel: Murda & Ezhel\n",
        "Sevecek Sandım: UZI\n",
        "Cuma: UZI\n",
        "Krvn: UZI\n",
        "Naptığını Bilmesem de: UZI\n",
        "Makina: UZI\n",
        "İstisnalar Kaideyi Bozmaz: Sagopa Kajmer\n",
        "Vasiyet: Sagopa Kajmer\n",
        "Ateşten Gömlek: Sagopa Kajmer\n",
        "\"\"\"\n",
        "\n",
        "# Bu metni bir Python sözlüğüne (dictionary) dönüştürme işlemi:\n",
        "sanatci_map = {} # Boş bir 'sanatçı haritası' sözlüğü oluştur.\n",
        "for line in user_text.strip().split('\\n'): # Metni satır satır oku\n",
        "    if ':' in line: # Sadece ':' içeren (eşleştirme olan) satırları işle\n",
        "        try:\n",
        "            # Satırı ':' karakterinden ikiye böl (Şarkı, Sanatçı)\n",
        "            sarki, sanatci = line.split(':', 1)\n",
        "\n",
        "            # Sözlüğe ekle: {'Şarkı Adı': 'Sanatçı Adı'}\n",
        "            # .strip() ile baş/sondaki boşlukları temizle.\n",
        "            sanatci_map[sarki.strip()] = sanatci.strip()\n",
        "        except ValueError:\n",
        "            # Kategori başlıkları ('Pop ve Rock' gibi) ':' içermez\n",
        "            # veya formatı bozuk satırlar varsa hata vermeden geç.\n",
        "            pass\n",
        "\n",
        "# Şimdi 'df_temiz' DataFrame'indeki 'sarki_adi' sütununu\n",
        "# bu 'sanatci_map' sözlüğü ile eşleştirerek YENİ bir 'sanatci' sütunu oluştur.\n",
        "df_enriched = df_temiz.copy() # Orijinal DataFrame'i koru, kopyasını al.\n",
        "df_enriched['sanatci'] = df_enriched['sarki_adi'].map(sanatci_map)\n",
        "\n",
        "# Eşleşme bulunamayan (sözlükte olmayan) şarkılar için 'sanatci' sütununa 'NaN'\n",
        "# yerine 'Bilinmiyor' yaz.\n",
        "df_enriched['sanatci'].fillna('Bilinmiyor', inplace=True)\n",
        "\n",
        "# DataFrame'i RAG için daha okunaklı bir sıraya koy.\n",
        "df_enriched = df_enriched[['sanatci', 'sarki_adi', 'kategori', 'sozler']]\n",
        "print(\"Veri seti 'sanatçı' bilgisi ile zenginleştirildi.\")\n",
        "\n",
        "\n",
        "# --- 4. Metinleri LangChain Document Nesnelerine Dönüştürme ---\n",
        "# Vektör veritabanına eklemeden önce, her şarkı sözünü\n",
        "# LangChain'in anladığı standart bir 'Document' formatına getirmeliyiz.\n",
        "documents = []\n",
        "# DataFrame'deki her bir satır (şarkı) için döngü başlat\n",
        "for index, row in df_enriched.iterrows():\n",
        "    # 'metadata', şarkı sözünün \"künyesidir\".\n",
        "    # Vektör veritabanı benzer bir söz parçası bulduğunda,\n",
        "    # bu metadata sayesinde o parçanın HANGİ ŞARKIYA ve KİME ait olduğunu bilecek.\n",
        "    metadata = {\n",
        "        \"sanatci\": str(row.get('sanatci')),\n",
        "        \"sarki_adi\": str(row.get('sarki_adi')),\n",
        "        \"kategori\": str(row.get('kategori'))\n",
        "    }\n",
        "\n",
        "    # 'page_content', asıl metnin (şarkı sözünün) kendisidir.\n",
        "    # 'metadata' ise o metne ait üst veridir.\n",
        "    doc = Document(page_content=row['sozler'], metadata=metadata)\n",
        "    documents.append(doc)\n",
        "\n",
        "print(f\"{len(documents)} adet şarkı LangChain Document nesnesine dönüştürüldü.\")\n",
        "\n",
        "# --- 5. Metinleri Parçalama (Splitting) ---\n",
        "# LLM'lerin (Gemini) bir 'context window' (bağlam penceresi) sınırı vardır.\n",
        "# Ayrıca, arama yaparken uzun bir şarkı sözünün tamamı yerine\n",
        "# sadece soruyla ilgili olan kısmını bulmak daha etkilidir.\n",
        "# Bu yüzden 'Document'ları daha küçük parçalara (chunks) böleriz.\n",
        "\n",
        "# DÜZELTME: Bu, doğru sonucu almamızı sağlayan en önemli ayarlardan biriydi.\n",
        "# Parçaları çok büyütmeden, ama anlamlı olacak şekilde bölüyoruz.\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,  # Her parçanın maksimum karakter sayısı.\n",
        "    chunk_overlap=50 # İki parça arasında 50 karakterlik kesişim bırak.\n",
        "                     # Bu, cümlenin ortadan ikiye bölünmesi durumunda\n",
        "                     # anlam bütünlüğünün kaybolmasını engeller.\n",
        ")\n",
        "\n",
        "# Tüm 'Document'ları (şarkıları) bu ayarlara göre parçala.\n",
        "splits = text_splitter.split_documents(documents)\n",
        "print(f\"{len(documents)} şarkı, {len(splits)} adet metin parçasına (chunk) bölündü.\")\n",
        "\n",
        "\n",
        "# --- 6. Embedding Modeli Yükleme ---\n",
        "# 'Embedding', metin parçalarını (sözleri) bilgisayarın anlayabileceği\n",
        "# anlamsal bir sayı dizisine (vektör) dönüştürme işlemidir.\n",
        "# \"all-MiniLM-L6-v2\", bu iş için optimize edilmiş, hızlı ve etkili\n",
        "# bir 'sentence-transformer' modelidir.\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "print(f\"'{model_name}' embedding modeli yüklendi.\")\n",
        "\n",
        "\n",
        "# --- 7. Vektör Veritabanı Oluşturma ve Kaydetme ---\n",
        "# Bu son adımda, oluşturduğumuz tüm 'splits' (metin parçaları)\n",
        "# 'embeddings' modeli kullanılarak vektöre dönüştürülür ve\n",
        "# 'Chroma' veritabanına kaydedilir.\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=splits,           # Vektöre dönüştürülecek metin parçaları\n",
        "    embedding=embeddings,       # Bu parçaları vektöre dönüştürecek model\n",
        "    persist_directory=\"chroma_db\" # Sonuçların kaydedileceği klasör adı\n",
        ")\n",
        "\n",
        "print(\"\\n✅✅✅ Başarılı! Vektör veritabanı oluşturuldu ve 'chroma_db' klasörüne kaydedildi.\")\n",
        "print(\"Artık bu notebook'u kapatabilir ve 'app.py' uygulamasını çalıştırabilirsiniz.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wGSQKvuM3br",
        "outputId": "23052e2e-eaa8-4827-fb7a-a6cf1966e402"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ HÜCRE 3: Veri seti hazırlanıyor ve vektör veritabanı SIFIRDAN oluşturuluyor...\n",
            "Veri seti 'Lyrics' klasörü zaten mevcut, indirme adımı atlandı.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Şarkılar okunuyor: 5it [00:00, 429.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "240 adet şarkı sözü okundu ve DataFrame oluşturuldu.\n",
            "Veri seti 'sanatçı' bilgisi ile zenginleştirildi.\n",
            "240 adet şarkı LangChain Document nesnesine dönüştürüldü.\n",
            "240 şarkı, 1277 adet metin parçasına (chunk) bölündü.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/tmp/ipython-input-257716938.py:368: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_enriched['sanatci'].fillna('Bilinmiyor', inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'sentence-transformers/all-MiniLM-L6-v2' embedding modeli yüklendi.\n",
            "\n",
            "✅✅✅ Başarılı! Vektör veritabanı oluşturuldu ve 'chroma_db' klasörüne kaydedildi.\n",
            "Artık bu notebook'u kapatabilir ve 'app.py' uygulamasını çalıştırabilirsiniz.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# HÜCRE 4: RAG ZİNCİRİNİN KURULMASI VE TEST EDİLMESİ\n",
        "# Amaç: Hücre 3'te oluşturduğumuz kalıcı 'chroma_db' veritabanını geri yüklemek\n",
        "#       ve LangChain Expression Language (LCEL) kullanarak modern, esnek bir\n",
        "#       RAG (Retrieval-Augmented Generation) zinciri (chain) kurmak.\n",
        "#       Bu hücre, 'app.py' dosyasında kullanacağımız RAG mantığının\n",
        "#       Colab üzerinde bir testidir.\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"▶️ HÜCRE 4: Modern zincir ile chatbot kuruluyor...\")\n",
        "\n",
        "# LCEL (LangChain Expression Language) için gerekli temel bileşenler\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "    # LLM'e (Gemini) göndereceğimiz talimat şablonunu oluşturmak için.\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "    # Kullanıcının sorusu gibi, bir girdiyi zincirin sonraki adımlarına\n",
        "    # HİÇ DEĞİŞTİRMEDEN \"olduğu gibi\" aktarmak için kullanılır.\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "    # LLM'in cevabını (genellikle bir 'ChatMessage' nesnesidir)\n",
        "    # bizim için basit bir 'string' (metin) haline getiren çıktı ayrıştırıcı.\n",
        "\n",
        "\n",
        "# --- 1. Veritabanını (Vectorstore) Yükleme ---\n",
        "# (Bu hücreyi çalıştırmadan önce HÜCRE 3'ün başarıyla bitmiş olması gerekir)\n",
        "# 'chroma_db' klasöründeki kalıcı veritabanını hafızaya yüklüyoruz.\n",
        "\n",
        "# Embedding modelini tekrar tanımlamalıyız, çünkü Chroma'nın\n",
        "# veritabanını yüklerken hangi modelle oluşturulduğunu bilmesi gerekir.\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "\n",
        "# 'persist_directory' ile veritabanını diskten yükle.\n",
        "vectorstore = Chroma(persist_directory=\"chroma_db\", embedding_function=embeddings)\n",
        "print(\"Kalıcı 'chroma_db' veritabanı başarıyla yüklendi.\")\n",
        "\n",
        "\n",
        "# --- 2. Retriever'ı (Getirici) Yapılandırma ---\n",
        "# 'Retriever', veritabanında (vectorstore) arama yapma mantığını tanımlar.\n",
        "\n",
        "# DÜZELTME: Bu, LLM'in kafasının karışmasını önleyen en kritik ayardı.\n",
        "# 'search_kwargs={\"k\": 1}' : Kullanıcının sorusuna en çok benzeyen\n",
        "# SADECE 1 (bir) adet metin parçasını (chunk) veritabanından getir.\n",
        "#\n",
        "# NEDEN k=1?\n",
        "# Eğer k=3 deseydik, LLM'e 3 farklı (belki alakasız) şarkı sözü parçası\n",
        "# gönderecektik. Bu, modelin kafasını karıştırıp yanlış cevap\n",
        "# (\"hallucination\") vermesine veya \"Şu şarkı da olabilir, bu da...\"\n",
        "# gibi belirsiz cevaplar vermesine neden oluyordu.\n",
        "# k=1'e odaklanmak, cevabın doğruluğunu ve netliğini maksimize etti.\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
        "\n",
        "\n",
        "# --- 3. Prompt Şablonunu (Talimat Metni) Oluşturma ---\n",
        "# Bu, RAG'ın \"Augmented\" (Geliştirme/Yönlendirme) kısmıdır.\n",
        "# LLM'e (Gemini) ne yapması gerektiğini tam olarak söylediğimiz talimat metni.\n",
        "template = \"\"\"\n",
        "Sana verilen Bağlam'ı kullanarak kullanıcının Soru'sunu cevapla. Cevabını SADECE bu bağlamdaki bilgilere dayanarak ver. Eğer bağlamda cevap yoksa, 'Bu konuda bilgim yok.' de.\n",
        "\n",
        "Bağlam:\n",
        "{context}\n",
        "\n",
        "Soru: {question}\n",
        "\n",
        "Cevap:\n",
        "\"\"\"\n",
        "# 'context' ve 'question' değişkenleri, zincir çalışırken\n",
        "# otomatik olarak doldurulacak yer tutuculardır.\n",
        "# 'SADECE' ve 'Bu konuda bilgim yok' talimatları, modelin\n",
        "# veritabanında olmayan bilgileri uydurmasını (hallucination) engeller.\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "\n",
        "# --- 4. LLM'i (Dil Modeli) Yükleme ---\n",
        "# DÜZELTME: Hesabının kullanabildiği, çalışan doğru model adını yazıyoruz.\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro-latest\",  # Kullanılacak Google Gemini modelinin adı.\n",
        "    temperature=0               # Modelin \"yaratıcılık\" seviyesi.\n",
        "                                # '0', modelin en olası ve gerçekçi cevabı\n",
        "                                # vermesini sağlar (uydurma yapmaz).\n",
        "                                # Sohbet için değil, RAG için 0 idealdir.\n",
        ")\n",
        "\n",
        "\n",
        "# --- 5. Tüm Parçaları Birleştirerek Modern Zinciri Oluşturma (LCEL) ---\n",
        "# LangChain Expression Language (LCEL), '|' (pipe) operatörünü kullanarak\n",
        "# adımları birbirine bağladığımız modern bir \"boru hattı\" sistemidir.\n",
        "# Okunuşu: \"Önce şunu yap, ÇIKTISINI al, bir sonrakine GİRDİ olarak ver.\"\n",
        "\n",
        "rag_chain = (\n",
        "    # ADIM 1: Girdileri Hazırla (Paralel Çalışır)\n",
        "    # Kullanıcı bir 'soru' (string) ile zinciri çağırır.\n",
        "    # Bu sözlük, o soruyu iki yere birden gönderir:\n",
        "    {\n",
        "     \"context\": retriever,           # 1. Soru 'retriever'a gider, 'context' (şarkı sözü) bulunur.\n",
        "     \"question\": RunnablePassthrough() # 2. Soru 'olduğu gibi' bir sonraki adıma aktarılır.\n",
        "    }\n",
        "\n",
        "    # ADIM 2: Prompt'u Doldur\n",
        "    # '|' (pipe): Adım 1'in çıktısı ('context' ve 'question') alınır\n",
        "    # ve 'prompt' şablonuna GİRDİ olarak verilir.\n",
        "    # Çıktı: Doldurulmuş, LLM'e hazır talimat metni.\n",
        "    | prompt\n",
        "\n",
        "    # ADIM 3: LLM'i Çalıştır\n",
        "    # '|' (pipe): Doldurulmuş prompt alınır ve 'llm'e (Gemini) GİRDİ olarak verilir.\n",
        "    # Çıktı: LLM'in cevabını içeren bir 'ChatMessage' nesnesi.\n",
        "    | llm\n",
        "\n",
        "    # ADIM 4: Çıktıyı Temizle\n",
        "    # '|' (pipe): 'ChatMessage' nesnesi alınır ve 'StrOutputParser'a verilir.\n",
        "    # Çıktı: Nihai cevap (basit bir string/metin).\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"✅ Modern chatbot (RAG zinciri) başarıyla kuruldu!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrsnE-Y5M4io",
        "outputId": "0fad895e-fcf4-466b-c44f-00a7227f2d60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ HÜCRE 4: Modern zincir ile chatbot kuruluyor...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kalıcı 'chroma_db' veritabanı başarıyla yüklendi.\n",
            "✅ Modern chatbot (RAG zinciri) başarıyla kuruldu!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# HÜCRE 5: ZİNCİRİ TEST ETME (SORU SORMA)\n",
        "# Amaç: Hücre 4'te kurduğumuz 'rag_chain'in RAG görevini\n",
        "#       (Metin bulma + Soru yanıtlama) doğru yapıp yapmadığını\n",
        "#       gerçek bir senaryo ile test etmek.\n",
        "# ==============================================================================\n",
        "\n",
        "# --- SORU SORMA KISMI ---\n",
        "\n",
        "# Test sorumuzu tanımlıyoruz.\n",
        "# Bu soru, RAG sistemimizin birden fazla yeteneğini test etmek için\n",
        "# özel olarak seçilmiştir:\n",
        "# 1. \"Aşkın kazanması için ayrı gitme\": Bu, veritabanında (ChromaDB)\n",
        "#    anlamsal arama (semantic search) yapılmasını tetikler.\n",
        "#    'retriever'ın doğru şarkı sözü parçasını bulması gerekir.\n",
        "# 2. \"...şarkı hangisi, kim söylüyor ve türü nedir?\": Bu kısım,\n",
        "#    LLM'in sadece bulduğu sözü (context) vermekle kalmayıp,\n",
        "#    o söze bağlı olan 'metadata'yı (Hücre 3'te eklediğimiz\n",
        "#    sanatci, sarki_adi, kategori) da okuyup, anlayıp,\n",
        "#    cevabına dahil etmesini test eder.\n",
        "soru = \"Aşkın kazanması için ayrı gitme' sözü geçen şarkı hangisi, kim söylüyor ve türü nedir?\"\n",
        "print(f\"\\nSoru: {soru}\")\n",
        "\n",
        "\n",
        "# --- ZİNCİRİ ÇALIŞTIRMA ---\n",
        "# 'rag_chain.invoke(soru)', Hücre 4'te tanımladığımız tüm boru hattını\n",
        "# (LCEL) baştan sona çalıştırır:\n",
        "#\n",
        "# 1. 'soru' alınır -> Retriever'a gider -> 'context' (şarkı sözü parçası) bulunur.\n",
        "# 2. 'soru' alınır -> RunnablePassthrough'dan geçer -> 'question' olarak kalır.\n",
        "# 3. 'context' ve 'question' -> PromptTemplate'e gider -> Doldurulmuş talimat metni oluşur.\n",
        "# 4. Doldurulmuş talimat metni -> LLM'e (Gemini) gider -> Model cevabı üretir (ChatMessage).\n",
        "# 5. Modelin cevabı -> StrOutputParser'a gider -> Cevap (string) elde edilir.\n",
        "#\n",
        "# Tüm bu işlemlerin sonucu 'cevap' değişkenine atanır.\n",
        "cevap = rag_chain.invoke(soru)\n",
        "\n",
        "\n",
        "# --- SONUCU GÖSTERME ---\n",
        "print(\"\\n--- CHATBOT'UN CEVABI ---\")\n",
        "# LLM'in (Gemini) ürettiği ve bizim Prompt ile yönlendirdiğimiz\n",
        "# (\"SADECE bağlamı kullan...\") nihai cevabı yazdır.\n",
        "print(cevap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wnIPJ1-OB0n",
        "outputId": "85de4203-a62e-47d4-8937-53420bb40acc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Soru: Aşkın kazanması için ayrı gitme' sözü geçen şarkı hangisi, kim söylüyor ve türü nedir?\n",
            "\n",
            "--- CHATBOT'UN CEVABI ---\n",
            "Şarkının adı 'Ayrı Gitme', sanatçısı Aleyna Tilki ve türü Pop'tur.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r chroma_db_GUNCEL.zip chroma_db"
      ],
      "metadata": {
        "id": "CYwUcAKbx6Ww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c57248-e293-472d-f03a-717673f1d219"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: chroma_db/ (stored 0%)\n",
            "  adding: chroma_db/chroma.sqlite3 (deflated 56%)\n",
            "  adding: chroma_db/29be6c24-7568-4bf2-8326-0651a474c28b/ (stored 0%)\n",
            "  adding: chroma_db/29be6c24-7568-4bf2-8326-0651a474c28b/header.bin (deflated 58%)\n",
            "  adding: chroma_db/29be6c24-7568-4bf2-8326-0651a474c28b/index_metadata.pickle (deflated 48%)\n",
            "  adding: chroma_db/29be6c24-7568-4bf2-8326-0651a474c28b/data_level0.bin (deflated 12%)\n",
            "  adding: chroma_db/29be6c24-7568-4bf2-8326-0651a474c28b/link_lists.bin (deflated 86%)\n",
            "  adding: chroma_db/29be6c24-7568-4bf2-8326-0651a474c28b/length.bin (deflated 97%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "So7OupWWm3eH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}